---
title: "EJEMPLO TAREA 9"
author: "EJEMPLO"
date: "2025-06-26"
output: html_document
---

```{r setup, include=FALSE}
library(carData)
library(ggplot2)
library(GGally)
library(caret)
library(dplyr)
library(car)
library(carData)
library(ggpubr)
library(leaps)
library(car)
```


# 0) LECTURA DE ARCHIVO Y SELECCIÓN DE DATOS:

```{r}
datos <- read.csv2("EP09 Datos.csv")
```

# 1) Definir la semilla a utilizar, que corresponde a los últimos cuatro dígitos del RUN (sin considerar el dígito verificador) del integrante de menor edad del equipo.

```{r}
set.seed(3959) 
```


# 2) Seleccionar una muestra aleatoria de 100 mujeres (si la semilla es un número par) o 100 hombres (si la semilla es impar), y separar 70 casos para trabajar en la construcción de modelos y 30 para su evaluación en datos no vistos.

```{r}
datos_hombres <- datos |> filter(Gender == 1) |> select(-Gender, -Height) |> sample_n(100) 

datos_entrenamiento <- datos_hombres |> slice_head(n = 70)

datos_prueba <- datos_hombres |> slice_tail(n = 30)
```


# 3) Seleccionar de forma aleatoria ocho posibles variables predictoras.

```{r}
# OBTENER NOMBRES DE COLUMNAS 
nombres_columnas <- colnames(datos_entrenamiento)

# SELECCIONAR 8 NOMBRES DE COLUMNAS DE FORMA ALEATORIA, DEJANDO PESO FUERA
nombres_tomados <- nombres_columnas[nombres_columnas != "Weight"] |> sample(8, replace = FALSE)

nombres_tomados

# OBTENER LOS DATOS DE LAS COLUMNAS SELECCIONADAS
datos_tomados <- datos_entrenamiento |> select(Weight, all_of(nombres_tomados))
```

# 4) Seleccionar, de las otras variables, una que el equipo considere que podría ser útil para predecir la variable Peso (sin considerar la estatura), justificando bien esta selección.

```{r}
# OBTENER LOS DATOS DE LAS COLUMNAS NO SELECCIONADAS
datos_restantes <- datos_entrenamiento |> select(-all_of(nombres_tomados), -Weight)

nombres_no_tomados <- colnames(datos_restantes)
nombres_no_tomados
```


# 5) Usando el entorno R y paquetes estándares1, construir un modelo de regresión lineal simple con el predictor seleccionado en el paso anterior.

## RLS USANDO VALIDACIÓN CRUZADA SIMPLE:
```{r}
# CONSIDERANDO COMO VARIABLE DEPENDIENE # "Peso" -> "Weight" USANDO "Hip.Girth" COMO PREDICTOR
modelo_rls_1 <- lm(Weight ~ Hip.Girth, data = datos_entrenamiento)
print(summary(modelo_rls_1))

#----------------------------------------------------------------------------------
cat("--------------------------------------------------------------\n")
# Calcular error cuadrado promedio para el conjunto de entrenamiento .
rmse_entrenamiento <- sqrt ( mean ( resid ( modelo_rls_1 )**2) )
cat ("MSE para el conjunto de entrenamiento:" , rmse_entrenamiento , "\n")

# Hacer predicciones para el conjunto de prueba .
predicciones <- predict ( modelo_rls_1 , datos_prueba )

# Calcular error cuadrado promedio para el conjunto de prueba .
error <- datos_prueba [["Weight"]] - predicciones
rmse_prueba <- sqrt ( mean ( error ** 2) )
cat ("MSE para el conjunto de prueba:       " , rmse_prueba )
```


## RLS USANDO VALIDACIÓN CRUZADA DE K PLIEGUES:
```{r}
# CONSIDERANDO COMO VARIABLE DEPENDIENE # "Peso" -> "Weight" USANDO "Hip.Girth" COMO PREDICTOR
entrenamiento <- train(Weight ~ Hip.Girth, 
                       data = datos_entrenamiento, 
                       method = "lm", 
                       trControl = trainControl(method = "cv", number = 10))

modelo_rls_2 <- entrenamiento[["finalModel"]]
print(summary(modelo_rls_2))

#----------------------------------------------------------------------------------
cat("--------------------------------------------------------------\n")
# Calcular error cuadrado promedio para el conjunto de entrenamiento .
rmse_entrenamiento <- sqrt ( mean ( resid ( modelo_rls_2 )**2) )
cat ("MSE para el conjunto de entrenamiento:" , rmse_entrenamiento , "\n")

# Hacer predicciones para el conjunto de prueba .
predicciones <- predict ( modelo_rls_2 , datos_prueba )

# Calcular error cuadrado promedio para el conjunto de prueba .
error <- datos_prueba [["Weight"]] - predicciones
rmse_prueba <- sqrt ( mean ( error ** 2) )
cat ("MSE para el conjunto de prueba:       " , rmse_prueba )
```


## RLS USANDO VALIDACIÓN CRUZADA DEJANDO UNO FUERA
```{r}
# CONSIDERANDO COMO VARIABLE DEPENDIENE # "Peso" -> "Weight" USANDO "Hip.Girth" COMO PREDICTOR
entrenamiento2 <- train(Weight ~ Hip.Girth, 
                       data = datos_entrenamiento, 
                       method = "lm", 
                       trControl = trainControl(method = "LOOCV"))

modelo_rls_3 <- entrenamiento2[["finalModel"]]
print(summary(modelo_rls_3))

#----------------------------------------------------------------------------------
cat("--------------------------------------------------------------\n")
# Calcular error cuadrado promedio para el conjunto de entrenamiento .
rmse_entrenamiento <- sqrt ( mean ( resid ( modelo_rls_3 )**2) )
cat ("MSE para el conjunto de entrenamiento:" , rmse_entrenamiento , "\n")

# Hacer predicciones para el conjunto de prueba .
predicciones <- predict ( modelo_rls_3 , datos_prueba )

# Calcular error cuadrado promedio para el conjunto de prueba .
error <- datos_prueba [["Weight"]] - predicciones
rmse_prueba <- sqrt ( mean ( error ** 2) )
cat ("MSE para el conjunto de prueba:       " , rmse_prueba )
```

### ESTUDIO DE CONFIAVILIDAD DE modelo_rls_1:

#### 1) PRUEBA DE HOMOCEDASTICIDAD:

```{r}
# Prueba de la varianza del error no constante
cat("\nPRUEBA DE HOMOCEDASTICIDAD:\n")
print (ncvTest(modelo_rls_1))
```

#### 2) DESPLEGAR GRÁFICOS DE RESIDUOS Y PRUEBAS DE CURVATURA:

```{r}
# GRÁFICOS DE RESIDUOS:
cat ("Pruebas de curvatura:\ n")
residualPlots(modelo_rls_1 , type = "rstandard" ,
              id = list ( method = "r", n = 3 , cex = 0.7 , location = "lr") ,
              col = "steelblue" , pch = 20 , col.quad = "red")

# GRÁFICOS MARGINALES:
marginalModelPlots(modelo_rls_1 , sd = TRUE ,
                   id = list ( method = "r", n = 3 , cex = 0.7 , location = "lr"),
                   col = "steelblue" , pch = 20 , col.line = c("steelblue" , "red") )
```

#### 3) PRUEBA DE INDEPENDENCIA DE LOS RESIDUOS:

```{r}
durbinWatsonTest(modelo_rls_1)
```

#### 4) DESPLEGAR GRÁFICOS DE INFLUENCIA:

```{r}
# Desplegar gráficos de influencia
casos_influyentes <- influencePlot(modelo_rls_1 , id = list(cex = 0.7))
#cat ("\nCasos que podrían ser influyentes:\n" )
print ( casos_influyentes )
```



# 6) Usando herramientas estándares1 para la exploración de modelos del entorno R, buscar entre dos y cinco predictores de entre las variables seleccionadas al azar en el punto 3, para agregar al modelo de regresión lineal simple obtenido en el paso 5.

## a) TOMA DE DATOS:

```{r}
nulo <- lm(Weight ~ 1, data = datos_tomados)
completo <- lm(Weight ~ ., data = datos_tomados)
```


## b) SELECCIÓN HACIA ADELANTE:

```{r}
cat("SELECCIÓN HACIA ADELANTE\n")
cat("-------------------------\n")
#-------------------------------------------------
# EVALUAR VARIABLE PARA EL PRIMER PREDICTOR:
paso <- add1(nulo, scope = completo, test = "F")
print(paso, digits = 3, signif.stars = FALSE) # <- ME MUESTRA LOS AIC DE LOS PREDICTORES

# AGREGAR LA VARIABLE QUE LOGRA LA MAYOR REDUCCIÓN DE AIC: (EL MENOR AIC)
modelo_seleccionado <- update(nulo, . ~ . + Thigh.Girth)
```

```{r}
#-------------------------------------------------
# EVALUAR VARIABLE PARA EL SEGUNDO PREDICTOR:
paso <- add1(modelo_seleccionado, scope = completo, test = "F")
cat("\n")
print(paso, digits = 3, signif.stars = FALSE) # <- ME MUESTRA LOS AIC DE LOS PREDICTORES

# AGREGAR LA VARIABLE QUE LOGRA LA MAYOR REDUCCIÓN DE AIC: (EL MENOR AIC)
modelo_seleccionado <- update(modelo_seleccionado, . ~ . + Navel.Girth)
```


```{r}
#-------------------------------------------------
# EVALUAR VARIABLE PARA EL TERCER PREDICTOR:
paso <- add1(modelo_seleccionado, scope = completo, test = "F")
cat("\n")
print(paso, digits = 3, signif.stars = FALSE) # <- ME MUESTRA LOS AIC DE LOS PREDICTORES

# AGREGAR LA VARIABLE QUE LOGRA LA MAYOR REDUCCIÓN DE AIC: (EL MENOR AIC)
modelo_seleccionado <- update(modelo_seleccionado, . ~ . + Ankles.diameter)
```


```{r}
#-------------------------------------------------
# EVALUAR VARIABLE PARA EL CUARTO PREDICTOR:
paso <- add1(modelo_seleccionado, scope = completo, test = "F")
cat("\n")
print(paso, digits = 3, signif.stars = FALSE) # <- ME MUESTRA LOS AIC DE LOS PREDICTORES

# AGREGAR LA VARIABLE QUE LOGRA LA MAYOR REDUCCIÓN DE AIC: (EL MENOR AIC)
modelo_seleccionado <- update(modelo_seleccionado, . ~ . + Biacromial.diameter)
```


```{r}
#-------------------------------------------------
# EVALUAR VARIABLE PARA EL QUINTO PREDICTOR:
paso <- add1(modelo_seleccionado, scope = completo, test = "F")
cat("\n")
print(paso, digits = 3, signif.stars = FALSE) # <- ME MUESTRA LOS AIC DE LOS PREDICTORES

# AGREGAR LA VARIABLE QUE LOGRA LA MAYOR REDUCCIÓN DE AIC: (EL MENOR AIC)
modelo_seleccionado <- update(modelo_seleccionado, . ~ . + Wrists.diameter)
```

### + PREDICTORES TOMADOS:
- Thigh.Girth
- Navel.Girth
- Ankles.diameter
- Biacromial.diameter
- Wrists.diameter

### + MOSTRAR COEFICIENTES DEL MODELO:

```{r}
#------------------------------------------------------------
# Mostrar los coeficientes del modelo conseguido
cat ("\nModelo obtenido: \n")
print (modelo_seleccionado [["coefficients"]])
```

## c) SELECCIÓN HACIA ATRÁS:

```{r}

```


# 7) Evaluar la bondad de ajuste (incluyendo el análisis de casos atípicos y casos influyentes) y la generalidad (condiciones para RLM) de los modelos y “arreglarlos” en caso de que presenten algún problema.

```{r}
# Evaluar la bondad de ajuste del modelo seleccionado
cat("\n-----------------------------------------------------------------\n")
# MOSTRAR SUMMARY DEL MODELO SELECCIONADO:
cat("\nRESUMEN DEL MODELO SELECCIONADO:\n")
cat("\n-----------------------------------------\n")
print(summary(modelo_seleccionado))
cat("\n-----------------------------------------------------------------\n")
# VALORES AIC Y BIC DEL MODELO SELECCIONADO:
cat("\nBONDAD DE AJUSTE DEL MODELO SELECCIONADO:\n")
cat("\n-----------------------------------------\n")
cat("AIC: ", AIC(modelo_seleccionado), "\n")
cat("BIC: ", BIC(modelo_seleccionado), "\n")
```
### ESTUDIO DE CONFIAVILIDAD DE modelo_seleccionado:

#### 1. La variable de respuesta debe ser cuantitativa y continua, sin restricciones para su variabilidad.

```{r}
str(datos$Weight)
```

#### 2. Los predictores deben ser cuantitativos o dicotómicos (de ahí la necesidad de variables indicadoras para manejar más de dos niveles).

```{r}
str(datos_tomados)
```

#### 3. Los predictores deben tener algún grado de variabilidad (su varianza no debe ser igual a cero). En otras palabras, no pueden ser constantes.

```{r}
# AMBOS DAN LO MIMSMO:
sapply(datos_tomados, var)

cat("--------------------------------------------------\n")

apply(datos_tomados, 2, var)
```

#### 4. Cada predictor debe estar relacionado linealmente con la respuesta.

```{r}
# GRAFICO DE RECIDUOS:
residualPlots(modelo_seleccionado,
              terms = ~ Thigh.Girth + Navel.Girth + Ankles.diameter + Biacromial.diameter + Wrists.diameter,
              id = list(method = "r", n = 3, cex = 0.7, location = "lr"),
              col = "steelblue", pch = 19, col.quad = "red")

# GRÁFICOS MARGINALES:
marginalModelPlots(modelo_seleccionado, sd = TRUE,
                   terms = ~ Thigh.Girth + Navel.Girth + Ankles.diameter + Biacromial.diameter + Wrists.diameter,
                   id = list(method = "r", n = 3, cex = 0.7, location = "lr"),
                   col = "steelblue", pch = 20, col.line = c("blue", "red"))
```

RESPUESTA DE ANALISIS DE RESIDUOS

#### 5. La distribución de los residuos debe ser cercana a la normal centrada en cero.

RESPUESTA DE ANALISIS DE RESIDUOS

#### 6. La variabilidad de los residuos debe ser aproximadamente constante (homocedasticidad).

```{r}
ncvTest(modelo_seleccionado)
```

#### 7. Los residuos deben ser independientes entre sí.

```{r}
durbinWatsonTest(modelo_seleccionado)
```

#### 8. No debe existir multicolinealidad. Esto significa que no deben darse relaciones lineales fuertes (co-eficientes de correlación altos) entre dos o más predictores.

```{r}
vif(modelo_seleccionado)
```

#### 9. Las estimaciones de los coeficientes del modelo no debe estar alterados por unos pocas observaciones
influyentes.

```{r}
# Desplegar gráficos de influencia
casos_influyentes <- influencePlot(modelo_seleccionado ,id = list(cex = 0.7))
#cat ("\nCasos que podrían ser influyentes:\n" )
print(casos_influyentes)
```


# 8) Evaluar el poder predictivo del modelo con los datos no utilizados para construirlo.

## RLS USANDO VALIDACIÓN CRUZADA SIMPLE:
```{r}
#----------------------------------------------------------------------------------
modelo_poder <- lm(Weight ~ Thigh.Girth + Navel.Girth + Ankles.diameter + Biacromial.diameter + Wrists.diameter, data = datos_entrenamiento)
cat("\n--------------------------------------------------------------\n")
cat("PODER PREDICTIVO DEL MODELO:\n")
print(summary(modelo_poder))
#----------------------------------------------------------------------------------
predicciones <- predict(modelo_poder, newdata = datos_prueba)
errores <- datos_prueba$Weight - predicciones
rmse <- sqrt(mean(errores^2))
mae <- mean(abs(errores))

cat("\n--------------------------------------------------------------\n")
cat("PREDICCIONES:\n")
print(predicciones)
cat("\n--------------------------------------------------------------\n")
cat("ERROR CUADRADO PROMEDIO (ERRORES):\n")
print(errores)
cat("\n--------------------------------------------------------------\n")
cat("ERROR CUADRADO PROMEDIO (RMSE): ", rmse, "\n")
cat("\n--------------------------------------------------------------\n")
cat("ERROR ABSOLUTO MEDIO (MAE): ", mae, "\n")
cat("\n--------------------------------------------------------------\n")
```

```{r}

```





