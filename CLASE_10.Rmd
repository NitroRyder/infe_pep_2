---
title: "Untitled"
author: "EJEMPLO"
date: "2025-06-22"
output: html_document
---

# 1) REGRESIÓN LINEAL MEDIANTE MÍNIMOS CUADRADOS

## A) Ajuste de un modelo de regresión lineal simple (RLS)

```{r}
library ( dplyr )
library ( ggpubr )

# Cargar y filtrar los datos
datos <- mtcars |> filter ( wt > 2 & wt < 5)

# Ajustar un modelo de RLS con R
modelo <- lm( hp ~ disp , data = datos )
print ( summary ( modelo ) )

# Graficar los datos y el modelo obtenido
g1 <- ggscatter ( datos , x = "disp", y = "hp",
                  color = "steelblue" , fill = "steelblue1" , alpha = 0.5 , size = 3 ,
                  ylab = "Potencia[hp]")

g1 <- g1 + geom_abline ( intercept = coef ( modelo ) [1] , slope = coef ( modelo ) [2] ,
                           color = "steelblue4")

g1 <- g1 + xlab ( bquote ("Volumen útil de los cilindros" ~ group ("[", "in"^3 , "]") ) )

# Definir valores del predictor para veh í culos no inclui dos
# en el conjunto mtcars .
disp <- c (169.694 , 230.214 , 79.005 , 94.085 , 343.085 ,
           136.073 , 357.305 , 288.842 , 223.128 , 129.217 ,
           146.432 , 193.474 , 376.874 , 202.566 , 114.928)

# Usar el modelo para predecir el rendimiento de otros modelos
potencia_est <- predict ( modelo , data.frame ( disp ) )

# Graficar los valores predichos
nuevos <- data.frame ( disp , hp = potencia_est )

g2 <- ggscatter ( nuevos , x = "disp", y = "hp",
                  color = "steelblue" , fill = "steelblue1" , alpha = 0.5 , size = 3 ,
                  ylab = "Potencia[hp ]")

g2 <- g2 + xlab ( bquote ("Volumen útil de los cilindros" ~ group ("[", "in"^3 , "]") ) )

# Unir los gr á ficos en uno solo
g1 <- ggpar ( g1 , xlim = c(75 , 405) , ylim = c(60 , 340) )
g2 <- ggpar ( g2 , xlim = c(75 , 405) , ylim = c(60 , 340) )

g <- ggarrange ( g1 , g2 , labels = c("Modelo" , "Predicciones") , hjust = c( -1.2 , -0.7) )
print ( g )
```

-----------------------------------------------------------------------------------
SIGNIFICANCIA DEL COEFICIENTE:
- El valor p de todos los predictores seleccionados son menores a 0.05, lo que indica que son 
  predictores significativos al presentar valores p de < 2e-16.
  
-----------------------------------------------------------------------------------
RESIDUOS:
- Los residuos indican cierta asimetría positiva (el valor máximo es bastante más alto que el mínimo: 147.845 vs. -62.382), lo que sugiere que puede haber algunos outliers positivos.

- El mediana cercana a 0 es buena (1.62), sugiere que no hay sesgo importante en los errores.

-----------------------------------------------------------------------------------
RESUMEN DEL MODELO:
- El modelo es estadísticamente significativo, y su predictor principal también lo es.

-----------------------------------------------------------------------------------

## B) Regresión lineal simple con un predictor dicotómico:

```{r}
library ( dplyr )
library ( ggpubr )

# Cargar y filtrar los datos
datos <- mtcars |> filter ( wt > 2 & wt < 5)

# Verificar correlaci ó n entre hp y dos variables dicot ó micas
print ( cor ( datos [ , c("hp", "am", "vs") ]) )

# Ajustar un modelo de RLS con R para el predictor " vs "
modelo_vs <- lm( hp ~ vs , data = datos )
print ( summary ( modelo_vs ) )

# Graficar el modelo de RLS obtenido
g1 <- ggscatter ( datos , x = "vs", y = "hp",
                  color = "steelblue" , fill = "steelblue1" , alpha = 0.5 , size = 3 ,
                  xlab = "Forma del motor" , ylab = "Potencia[hp]" , xticks.by = 1)

g1 <- g1 + geom_abline ( intercept = coef ( modelo_vs )[1] , slope = coef ( modelo_vs )[2] ,
                           color = "steelblue4")
print ( g1 )

# Graficar los residuos del modelo
residuos <- modelo_vs [["residuals" ]]
datos <- cbind ( datos , residuos )

g2 <- ggscatter ( datos , x = "vs", y = "residuos" ,
                  color = "steelblue" , fill = "steelblue1" , alpha = 0.5 , size = 3 ,
                  xlab = "Forma del motor" , ylab = "Residuos[hp]" , xticks.by = 1)

g2 <- g2 + geom_hline ( yintercept = 0 , color = "steelblue4")

# Unir los gr á ficos en uno solo
g <- ggarrange ( g1 , g2 , labels = c("Modelo" , "Residuos") , hjust = c( -1.4 , -1.2) )
print ( g )
```

-----------------------------------------------------------------------------------
AJUSTE:
- R² (Multiple R-squared) = 0.4144: el modelo explica el 41.4% de la variabilidad del hm 

Este valor indica un ajuste bajo, lo que sugiere que hay otros factores que también influyen en hp y no están siendo considerados en el modelo.

-----------------------------------------------------------------------------------
SIGNIFICANCIA DEL COEFICIENTE:
- El valor p de todos los predictores seleccionados son menores a 0.05, lo que indica que son 
  predictores significativos al presentar valores p de 0.000517.

-----------------------------------------------------------------------------------
SIGNIFICANCA DEL MODELO:
- F-static presenta un p-value de 0.0005168
  
-----------------------------------------------------------------------------------
RESIDUOS:
- Los residuos indican cierta asimetría positiva (el valor máximo es bastante más alto que el mínimo: 150.667 vs. -93.333), lo que sugiere que puede haber algunos outliers positivos.

-----------------------------------------------------------------------------------
RESUMEN DEL MODELO:

- El modelo es estadísticamente significativo, y su predictor principal también lo es.
- Sin embargo, la capacidad explicativa del modelo es limitada (R² = 41.4%).

-----------------------------------------------------------------------------------


## C) Evaluación del modelo de regresión lineal simple usado como ejemplo.

### 1) DEFINICIÓN DE LM:

```{r}
library ( car )
library ( dplyr )
library ( ggpubr )

# Cargar y filtrar los datos .
datos <- mtcars |> filter ( wt > 2 & wt < 5)

# Ajustar modelo con R .
modelo <- lm( hp ~ disp , data = datos )
modelo
```


### 2) DESPLEGAR GRÁFICOS DE RESIDUOS Y PRUEBAS DE CURVATURA:

```{r}
# Desplegar gr á ficos de residuos y mostrar pruebas de curvatura .
cat ("Pruebas de curvatura:\ n")
residualPlots ( modelo , type = "rstandard" ,
                id = list ( method = "r", n = 3 , cex = 0.7 , location = "lr") ,
                col = "steelblue" , pch = 20 , col.quad = "red")
```

Grafico de reciduos:
Si bien es posible observar que presenta una curvatura, el test de curvatura de Tukey no es significativo, pues 
presenta un valor de 0.7054, uno mayor a 0.05, lo que refuerza la conclusión de que la relación entre los predictores seleccionados y hp puede ser considerada lineal para fines del modelo.

Cumpliendo con la condición de los residuos.

### 3) PRUEBA DE INDEPENDENCIA DE LOS RESIDUOS:

H0: Los residuos son independientes.
H1: Los residuos no son independientes.

```{r}
# Verificar independencia de los residuos
set.seed (19)
db <- durbinWatsonTest ( modelo )
cat ("\nPrueba de independencia:\n" )
print ( db )
```

Como el valor p es mayor a 0.05, no se rechaza H0. Por lo tanto, los residuos son independientes.

### 4) DESPLEGAR GRÁFICOS MARGINALES:

```{r}
# Desplegar gr á ficos marginales .
marginalModelPlots ( modelo , sd = TRUE ,
                     id = list ( method = "r", n = 3 , cex = 0.7 , location = "lr") ,
                     col = "steelblue" , pch = 20 , col.line = c("steelblue" , "red") )
```

Grafico marginales:
La relación es lineal, con un ajuste preciso y sin patrones de curvatura. Por tanto, el supuesto de linealidad está bien cumplido

Cumpliendio con la condición de linealidad de los predictores con la variable de respuesta.

DETALLE:
En las figuras se puede observar algunas desviaciones entre las observaciones y las predicciones, en una
región donde solo aparecen valores por debajo de la línea de regresión. Por otro lado, las estimaciones de las
desviaciones estándar sugieren que la variabilidad va aumentando con el valor de la variable predictora.

### 5) PRUEBA DE HOMOCEDASTICIDAD:

H0: La varianza de los residuos es constante (homocedasticidad).
H1: La varianza de los residuos no es constante (heterocedasticidad).

```{r}
# Prueba de la varianza del error no constante .
cat ("\nPrueba de homocedasticidad:\n" )
print ( ncvTest ( modelo ) )
```

Como el valor p es menor a 0.05, se rechaza H0. No cumpliendo con la condición de homocedasticidad.

### 6) DESPLEGAR GRÁFICOS DE INFLUENCIA:

```{r}
# Desplegar gr á ficos de influencia .
casos_influyentes <- influencePlot ( modelo , id = list ( cex = 0.7) )
#cat ("\nCasos que podrían ser influyentes:\n" )
print ( casos_influyentes )
```

Es posible observar que si bien los puntos Fiat 128, Pontiac Firebird, Ferrari Dino y Maserati Bora destacan por
sobre el resto, donde las observación Maserati Bora presenta residuos(StudRes) mayor a 2 lo cual las 
clasifica como potencialmente atípica, pero ninguna de las observaciones 
supera el umbral crítico en la distancia de Cook, siendo todos estos menores 
a 1, por ende no se consideran altamente influyentes ni comprometen 
significativamente la validez del modelo.

### 7) RESULTADO CONFIAVILIDAD:

NO SE CUMPLE CON LA CONDICIÓN DE HOMOCEDASTICIDAD, por lo que no se puede confiar en los resultados del modelo.

## D) RLS:

### 1) RLS usando validación cruzada:

```{r}
library ( dplyr )

# Cargar y filtrar los datos
datos <- mtcars |> filter ( wt > 2 & wt < 5)
n <- nrow ( datos )

# Crear conjuntos de entrenamiento y prueba .
set.seed (101)
n_entrenamiento <- floor (0.8 * n )
i_entrenamiento <- sample.int ( n = n , size = n_entrenamiento , replace = FALSE )
entrenamiento <- datos [i_entrenamiento, ]
prueba <- datos [ - i_entrenamiento, ]

# Ajustar y mostrar el modelo con el conjunto de entrenamiento .
modelo <- lm( hp ~ disp , data = entrenamiento )
print ( summary ( modelo ) )

#----------------------------------------------------------------------------------
cat("--------------------------------------------------------------\n")
# Calcular error cuadrado promedio para el conjunto de entrenamiento .
rmse_entrenamiento <- sqrt ( mean ( resid ( modelo )**2) )
cat ("MSE para el conjunto de entrenamiento:" , rmse_entrenamiento , "\n")

# Hacer predicciones para el conjunto de prueba .
predicciones <- predict ( modelo , prueba )

# Calcular error cuadrado promedio para el conjunto de prueba .
error <- prueba [[ "hp"]] - predicciones
rmse_prueba <- sqrt ( mean ( error ** 2) )
cat ("MSE para el conjunto de prueba:" , rmse_prueba )
```

-----------------------------------------------------------------------------------
AJUSTE:
- R² (Multiple R-squared) = 0.3825: el modelo explica el 38.3% de la variabilidad del hp. 

Este valor indica un ajuste bajo, lo que sugiere que hay otros factores que también influyen en hp y no están siendo considerados en el modelo.

-----------------------------------------------------------------------------------
SIGNIFICANCIA DEL COEFICIENTE:
- El valor p del predictor disp es menor a 0.05, lo que indica que es un 
  predictor significativo al presentar un valor p de 0.00365.

-----------------------------------------------------------------------------------
SIGNIFICANCA DEL MODELO:
- F-static presenta un p-value de 0.003653

-----------------------------------------------------------------------------------
ERROR CUADRÁTICO MEDIO (MSE):
- MSE para el conjunto de entrenamiento: 45.29314 
- MSE para el conjunto de prueba: 45.2879

Como son similares, podemos concluir que el modelo no está sobreajustado.

-----------------------------------------------------------------------------------
RESIDUOS:
- Los residuos indican cierta asimetría positiva (el valor máximo es bastante más alto que el mínimo: 161.66 vs. -48.96), lo que sugiere que puede haber algunos outliers positivos.

-----------------------------------------------------------------------------------

CONCLUSIÓN MODELO:

- El modelo es estadísticamente significativo, y su predictor principal también lo es.
- Sin embargo, la capacidad explicativa del modelo es limitada (R² = 38%).


### 2) RLS usando validación cruzada de K pliegues.

```{r}
library ( caret )
library ( dplyr )

# Cargar y filtrar los datos
datos <- mtcars |> filter ( wt > 2 & wt < 5)
n <- nrow ( datos )

# Ajustar y mostrar el modelo usando validaci ó n cruzada de 5 pliegues
set.seed (111)
entrenamiento <- train ( hp ~ disp , data = datos , method = "lm",
                         trControl = trainControl ( method = "cv", number = 5) )
modelo <- entrenamiento [[ "finalModel" ]]
print ( summary ( modelo ) )

#----------------------------------------------------------------------------------
cat("--------------------------------------------------------------\n")
# Mostrar los resultados de cada pliegue
cat ("Errores en cada pliegue:\n")
print ( entrenamiento [[ "resample" ]])

# Mostrar el resultado estimado para el modelo
cat ("\nError estimado para el modelo:\n" )
print ( entrenamiento [[ "results" ]])
```

-----------------------------------------------------------------------------------
ERRORES ESTIMADO PARA EL MODELO:
- RMSE = 47.53: el error cuadrático medio indica, en promedio, cuánto difieren las predicciones del valor real del hp.

- MAE = 32.28: el error absoluto medio representa la desviación promedio sin considerar el signo de los errores.

-----------------------------------------------------------------------------------
AJUSTE:
- R² (Multiple R-squared) = 0.5534: el modelo explica el 55.3% de la variabilidad del hp. 

Hay un ajuste Moderado para el modelo.

-----------------------------------------------------------------------------------
SIGNIFICANCIA DEL COEFICIENTE:
- El valor p del predictor disp es menor a 0.05, lo que indica que es un 
  predictor significativo al presentar un valor p de 2.02e-05.

-----------------------------------------------------------------------------------
SIGNIFICANCA DEL MODELO:
- F-static presenta un p-value de 2.02e-05

-----------------------------------------------------------------------------------
RESIDUOS:
- Los residuos indican cierta asimetría positiva (el valor máximo es bastante más alto que el mínimo: 147.845 vs. -62.382), lo que sugiere que puede haber algunos outliers positivos.

-----------------------------------------------------------------------------------
CONCLUSIÓN MODELO:

- El modelo es estadísticamente significativo, y su predictor principal también lo es.
- Sin embargo, la capacidad explicativa del modelo es moderada (R² = 55.3%) y errores razonables, sin evidencia de sobreajuste.

### 3) RLS usando validación cruzada dejando uno fuera.

```{r}
library ( caret )
library ( dplyr )

# Cargar y filtrar los datos
datos <- mtcars |> filter ( wt > 2 & wt < 5)
n <- nrow ( datos )

# Ajustar y mostrar el modelo usando validaci ó n cruzada dejando uno fuera
set.seed (111)
entrenamiento <- train ( hp ~ disp , data = datos , method = "lm",
                         trControl = trainControl ( method = "LOOCV") )
modelo <- entrenamiento [[ "finalModel" ]]
print ( summary ( modelo ) )

#----------------------------------------------------------------------------------
cat("--------------------------------------------------------------\n")
# Mostrar las predicciones para cada observaci ó n
cat ("Predicciones en cada pliegue:\n" )
print ( entrenamiento [[ "pred" ]])

# Mostrar el resultado estimado para el modelo
cat ("\nError estimado para el modelo:\n" )
print ( entrenamiento [[ "results" ]])
```

-----------------------------------------------------------------------------------
ERRORES ESTIMADO PARA EL MODELO:
- RMSE = 47.53: el error cuadrático medio indica, en promedio, cuánto difieren las predicciones del valor real del hp.

- MAE = 32.28: el error absoluto medio representa la desviación promedio sin considerar el signo de los errores.

-----------------------------------------------------------------------------------
AJUSTE:
- R² (Multiple R-squared) = 0.5534: el modelo explica el 55.3% de la variabilidad del hp. 

Hay un ajuste Moderado para el modelo.

-----------------------------------------------------------------------------------
SIGNIFICANCIA DEL COEFICIENTE:
- El valor p del predictor disp es menor a 0.05, lo que indica que es un 
  predictor significativo al presentar un valor p de 2.02e-05.

-----------------------------------------------------------------------------------
SIGNIFICANCA DEL MODELO:
- F-static presenta un p-value de 2.02e-05

-----------------------------------------------------------------------------------
RESIDUOS:
- Los residuos indican cierta asimetría positiva (el valor máximo es bastante más alto que el mínimo: 147.845 vs. -62.382), lo que sugiere que puede haber algunos outliers positivos.

-----------------------------------------------------------------------------------
CONCLUSIÓN MODELO:

- El modelo es estadísticamente significativo, y su predictor principal también lo es.
- Sin embargo, la capacidad explicativa del modelo es moderada (R² = 55.3%) y errores razonables, sin evidencia de sobreajuste.

### --------------------
### EXTRA:
### --------------------
### 4) RLS CON BOOTSTRAP

```{r}
library(boot)

# Función que retorna el coeficiente de pendiente para una muestra bootstrap
slope_fn <- function(data, indices) {
  d <- data[indices, ]  # Muestra bootstrap
  modelo <- lm(hp ~ disp, data = d)
  return(coef(modelo)[2])  # pendiente
}

# Aplicar bootstrapping con 1000 repeticiones
set.seed(123)
resultados <- boot(data = mtcars, statistic = slope_fn, R = 1000)

# Resumen
print(resultados)

# Intervalo de confianza bootstrap (percentil)
boot.ci(resultados, type = "perc")
```
